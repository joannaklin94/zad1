1+2
math
int x
x
x=3
x+1
line(2)
line(2,3)
abline()
plot.new(abline(1,2))
plot.new(abline())
plot(c(-2,3), c(-1,5), type = "n", xlab = "x", ylab = "y", asp = 1)
abline(h = 0, v = 0, col = "gray60")
library(class)
library(gmodels)
#----------------------exploring and preparing the data----------------------
setwd("C:/Users/joann/Desktop/4GL/zad1")
# first column (id) is obsolete
mydata = read.csv("dataset_cancer_diagnosis.csv")
mydata <- mydata[-1]
mydata$diagnosis <- factor(mydata$diagnosis, levels = c("B", "M"), labels = c("Benign", "Malignant"));
# normalization needs to be applied to rescale the attributes
normalize <- function(x) {	return ((x - min(x)) / (max(x) - min(x)))	}
mydata_normalized <- as.data.frame(lapply(mydata[2:31], normalize))
# data is split into two sets: 469 records for learning and 100 records for testing
mydata_train <- mydata_normalized[1:469, ]
mydata_test <- mydata_normalized[470:569, ]
# labels which store the diagnosis factor
mydata_train_labels <- mydata[1:469, 1]
mydata_test_labels <- mydata[470:569, 1]
#----------------------training a model on the data----------------------
#k=21
mydata_test_pred_21 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=21)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_21, prop.chisq=FALSE)$t
list_false_negatives <- cross[2]
list_false_positives <- cross[3]
#----------------------improving model performance----------------------
#k=1
mydata_test_pred_1 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=1)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_1, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=3
mydata_test_pred_3 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=3)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_3, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=5
mydata_test_pred_5 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=5)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_5, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=7
mydata_test_pred_7 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=7)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_7, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=9
mydata_test_pred_9 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=9)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_9, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=11
mydata_test_pred_11 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=11)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_11, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=13
mydata_test_pred_13 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=13)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_13, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=15
mydata_test_pred_15 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=15)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_15, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
#k=27
mydata_test_pred_27 <- knn(train = mydata_train, test = mydata_test,cl = mydata_train_labels, k=27)
cross = CrossTable(x = mydata_test_labels, y = mydata_test_pred_27, prop.chisq=FALSE)$t
list_false_negatives <- append(list_false_negatives, cross[2])
list_false_positives <- append(list_false_positives, cross[3])
# drawing two plots to find the best k
x <- c(21, 1, 3, 5, 7, 9, 11, 13, 15, 27)
y1 <- list_false_negatives
y2 <- list_false_positives
plot(x,y1, type = "p",col = "blue", xlab = "k", ylab = "number of false negatives", main = "False negative results vs. k")
plot(x,y2, type = "p",col = "blue", xlab = "k", ylab = "number of false positives", main = "False positive results vs. k")
library(e1071)
library(caret)
library(gmodels)
#----------------------exploring and preparing the data----------------------
setwd("C:/Users/joann/Desktop/4GL/zad1")
mydata = read.csv("dataset_cancer_diagnosis.csv")
mydata <- mydata[-1]
# data is split into two sets: 469 records for learning and 100 records for testing
mydata_train <- mydata[1:469, ]
mydata_test <- mydata[470:569, ]
#----------------------training a model on the data----------------------
classifier <- naiveBayes(mydata_train[ ,-1], mydata_train[ ,1])
predictor <- predict(classifier, mydata_test[ ,-1], type="class")
#table(mydata_test$diagnosis, predictor, dnn=list('predicted','actual'))
CrossTable(x = mydata_test$diagnosis, y = predictor, prop.chisq=FALSE)
classifier$apriori  # shows class distribution
classifier$tables$texture_mean
plot(function(x) dnorm(x, 17.55, 3.64), -5, 40, col="red", ylab="density", xlab="texture mean", main="Mean texture distribution for benign and malignant tumor")
par(new = TRUE)
plot(function(x) dnorm(x, 21.5, 3.8), -5, 40, col="green", ylab="density", xlab="texture mean")
legend("topright", c("benign tumor", "malignant tumor"), col = c("red", "green"), lwd=1)
print(confusionMatrix(predictor, mydata_test$diagnosis, positive="M", dnn=list('prediction','M')))
library(e1071)
#library(caret)
library(gmodels)
#----------------------exploring and preparing the data----------------------
setwd("C:/Users/joann/Desktop/4GL/zad1")
mydata = read.csv("dataset_cancer_diagnosis.csv")
mydata <- mydata[-1]
# data is split into two sets: 469 records for learning and 100 records for testing
mydata_train <- mydata[1:469, ]
mydata_test <- mydata[470:569, ]
#----------------------training a model on the data----------------------
classifier <- naiveBayes(mydata_train[ ,-1], mydata_train[ ,1])
predictor <- predict(classifier, mydata_test[ ,-1], type="class")
#table(mydata_test$diagnosis, predictor, dnn=list('predicted','actual'))
CrossTable(x = mydata_test$diagnosis, y = predictor, prop.chisq=FALSE)
classifier$apriori  # shows class distribution
classifier$tables$texture_mean
plot(function(x) dnorm(x, 17.55, 3.64), -5, 40, col="red", ylab="density", xlab="texture mean", main="Mean texture distribution for benign and malignant tumor")
par(new = TRUE)
plot(function(x) dnorm(x, 21.5, 3.8), -5, 40, col="green", ylab="density", xlab="texture mean")
legend("topright", c("benign tumor", "malignant tumor"), col = c("red", "green"), lwd=1)
print(confusionMatrix(predictor, mydata_test$diagnosis, positive="M", dnn=list('prediction','M')))
View(mydata)
library(kernlab)
library(gmodels)
#----------------------exploring and preparing the data----------------------
setwd("C:/Users/joann/Desktop/4GL/zad1")
mydata = read.csv("dataset_cancer_diagnosis.csv")
mydata <- mydata[-1]
mydata_train <- mydata[1:469, ]
mydata_test <- mydata[470:569, ]
#----------------------training a model on the data----------------------
svm_model_linear <- ksvm(diagnosis ~ ., data=mydata_train, kernel="vanilladot")
pred <- predict(svm_model_linear, mydata_test, type="response")
CrossTable(x = mydata_test$diagnosis, y = pred, prop.chisq=FALSE)
#----------------------improving model performance----------------------
svm_model_polynomial <- ksvm(diagnosis ~ ., data=mydata_train, kernel="polydot")
pred <- predict(svm_model_polynomial, mydata_test, type="response")
table(pred,mydata_test$diagnosis)
svm_model_RBF <- ksvm(diagnosis ~ ., data=mydata_train, kernel="rbfdot")
pred <- predict(svm_model_RBF, mydata_test, type="response")
table(pred,mydata_test$diagnosis)
svm_tune <- tune(svm, train.x=mydata_train, train.y=mydata_test,
kernel="vanilladot", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
print(svm_tune)
library(kernlab)
library(gmodels)
#----------------------exploring and preparing the data----------------------
setwd("C:/Users/joann/Desktop/4GL/zad1")
mydata = read.csv("dataset_cancer_diagnosis.csv")
mydata <- mydata[-1]
mydata_train <- mydata[1:469, ]
mydata_test <- mydata[470:569, ]
#----------------------training a model on the data----------------------
svm_model_linear <- ksvm(diagnosis ~ ., data=mydata_train, kernel="vanilladot")
pred <- predict(svm_model_linear, mydata_test, type="response")
CrossTable(x = mydata_test$diagnosis, y = pred, prop.chisq=FALSE)
#----------------------improving model performance----------------------
svm_model_polynomial <- ksvm(diagnosis ~ ., data=mydata_train, kernel="polydot")
pred <- predict(svm_model_polynomial, mydata_test, type="response")
table(pred,mydata_test$diagnosis)
svm_model_RBF <- ksvm(diagnosis ~ ., data=mydata_train, kernel="rbfdot")
pred <- predict(svm_model_RBF, mydata_test, type="response")
table(pred,mydata_test$diagnosis)
library(e1071)
#library(caret)
library(gmodels)
#----------------------exploring and preparing the data----------------------
setwd("C:/Users/joann/Desktop/4GL/zad1")
mydata = read.csv("dataset_cancer_diagnosis.csv")
mydata <- mydata[-1]
# data is split into two sets: 469 records for learning and 100 records for testing
mydata_train <- mydata[1:469, ]
mydata_test <- mydata[470:569, ]
#----------------------training a model on the data----------------------
classifier <- naiveBayes(mydata_train[ ,-1], mydata_train[ ,1])
predictor <- predict(classifier, mydata_test[ ,-1], type="class")
CrossTable(x = mydata_test$diagnosis, y = predictor, prop.chisq=FALSE)
classifier$apriori  # shows class distribution
classifier$tables$texture_mean
plot(function(x) dnorm(x, 17.55, 3.64), -5, 40, col="red", ylab="density", xlab="texture mean", main="Mean texture distribution for benign and malignant tumor")
par(new = TRUE)
plot(function(x) dnorm(x, 21.5, 3.8), -5, 40, col="green", ylab="density", xlab="texture mean")
legend("topright", c("benign tumor", "malignant tumor"), col = c("red", "green"), lwd=1)
print(confusionMatrix(predictor, mydata_test$diagnosis, positive="M", dnn=list('prediction','M')))
library(e1071)
#library(caret)
library(gmodels)
#----------------------exploring and preparing the data----------------------
setwd("C:/Users/joann/Desktop/4GL/zad1")
mydata = read.csv("dataset_cancer_diagnosis.csv")
mydata <- mydata[-1]
# data is split into two sets: 469 records for learning and 100 records for testing
mydata_train <- mydata[1:469, ]
mydata_test <- mydata[470:569, ]
#----------------------training a model on the data----------------------
classifier <- naiveBayes(mydata_train[ ,-1], mydata_train[ ,1])
predictor <- predict(classifier, mydata_test[ ,-1], type="class")
CrossTable(x = mydata_test$diagnosis, y = predictor, prop.chisq=FALSE)
classifier$apriori  # shows class distribution
classifier$tables$texture_mean
plot(function(x) dnorm(x, 17.55, 3.64), -5, 40, col="red", ylab="density", xlab="texture mean", main="Mean texture distribution for benign and malignant tumor")
par(new = TRUE)
plot(function(x) dnorm(x, 21.5, 3.8), -5, 40, col="green", ylab="density", xlab="texture mean")
legend("topright", c("benign tumor", "malignant tumor"), col = c("red", "green"), lwd=1)
print(confusionMatrix(predictor, mydata_test$diagnosis, positive="M", dnn=list('prediction','M')))
